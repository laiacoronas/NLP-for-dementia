{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. CODIFY THE TEXT USING BERT\n",
    "\n",
    "Python 3.8\n",
    "\n",
    "De forma local optimiza el uso del GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Hidden State Shape: (1, 171, 768)\n"
     ]
    }
   ],
   "source": [
    "text = \"the scene is in the in the kitchen . the mother is wiping dishes and the water is running on the floor . a child is trying to get a boy is trying to get cookies outta a jar and hes about to tip over on a stool . uh the little girl is reacting to his falling . uh it seems to be summer out . the window is open . the curtains are blowing . it must be a gentle breeze . theres grass outside in the garden . uh mothers finished certain of the the dishes . kitchens very tidy . the mother seems to have nothing in the house to eat except cookies in the cookie jar . uh the children look to be almost about the same size . perhaps theyre twins . theyre dressed for summer warm weather . um you want more the mothers in a short sleeve dress . Ill hafta say its warm .\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertConfig, TFBertModel, BertTokenizer\n",
    "\n",
    "custom_config = BertConfig(\n",
    "    vocab_size=30522,               \n",
    "    num_attention_heads=12,         \n",
    "    num_hidden_layers=12,          \n",
    "    attention_probs_dropout_prob=0.1,  \n",
    "    hidden_size=768,                \n",
    "    intermediate_size=3072,        \n",
    "    hidden_dropout_prob=0.1,        \n",
    "    hidden_act=\"relu\",              \n",
    "    max_position_embeddings=512    \n",
    ")\n",
    "\n",
    "model = TFBertModel(custom_config)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\n",
    "    text,\n",
    "    return_tensors=\"tf\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "bert_outputs = model(**inputs)\n",
    "\n",
    "bert_last_hidden_state = bert_outputs.last_hidden_state \n",
    "bert_pooled_output = bert_outputs.pooler_output        \n",
    "\n",
    "print(\"Last Hidden State Shape:\", bert_last_hidden_state.shape)\n",
    "\n",
    "# shape: number of samples is 1, number of tokens is 171 and size of the embedding vector is 768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. CNN TEXT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Vector Shape: (1, 260)\n"
     ]
    }
   ],
   "source": [
    "class TextCNN(tf.keras.Model):\n",
    "    def __init__(self, dropout_prob=0.5):\n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        # convolution kernels\n",
    "        self.conv1 = tf.keras.layers.Conv2D(130, (5, 768), activation='relu')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(130, (10, 768), activation='relu')\n",
    "        self.conv3 = tf.keras.layers.Conv2D(130, (15, 768), activation='relu')\n",
    "        self.conv4 = tf.keras.layers.Conv2D(130, (20, 768), activation='relu')\n",
    "\n",
    "        # max pooling\n",
    "        self.pool = tf.keras.layers.GlobalMaxPooling2D()\n",
    "\n",
    "        # fusion layer\n",
    "        self.fc = tf.keras.layers.Dense(260, activation='relu')\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_prob)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # input the output of the bert model\n",
    "        x = tf.expand_dims(inputs, -1) \n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x4 = self.conv4(x)\n",
    "        \n",
    "        # pool the outputs of the convolution layers \n",
    "        pooled_1 = self.pool(x1)\n",
    "        pooled_2 = self.pool(x2)\n",
    "        pooled_3 = self.pool(x3)\n",
    "        pooled_4 = self.pool(x4)\n",
    "        \n",
    "        # fusion of all the features\n",
    "        fused_features = tf.concat([pooled_1, pooled_2, pooled_3, pooled_4], axis=-1)\n",
    "\n",
    "        feature_vector = self.fc(fused_features)\n",
    "        feature_vector = self.dropout(feature_vector)\n",
    "        \n",
    "        return feature_vector\n",
    "\n",
    "textcnn_model = TextCNN()\n",
    "feature_vector_cnn = textcnn_model(bert_last_hidden_state)  \n",
    "print(\"Feature Vector Shape:\", feature_vector_cnn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. LTSM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del vector de características (LSTM): (1, 260)\n"
     ]
    }
   ],
   "source": [
    "lstm_units = 260 \n",
    "dropout_rate = 0.5\n",
    "\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=bert_last_hidden_state.shape[1:]), \n",
    "    tf.keras.layers.LSTM(\n",
    "        units=lstm_units,\n",
    "        activation='relu',          \n",
    "        return_sequences=False      \n",
    "    ),\n",
    "    tf.keras.layers.Dropout(dropout_rate)  \n",
    "])\n",
    "\n",
    "lstm_features = lstm_model(bert_last_hidden_state)\n",
    "print(\"Shape del vector de características (LSTM):\", lstm_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to concatenate the CNN + LTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Feature Vector Shape: (1, 520)\n"
     ]
    }
   ],
   "source": [
    "concatenated_vector = tf.concat([lstm_features, feature_vector_cnn], axis=-1)\n",
    "print(\"Concatenated Feature Vector Shape:\", concatenated_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the fused features need to be passed into the fully connected layer first, and the Softmax classifier is used for the classification task. The dimension of the output vector must be the same as the number of categories (2 in this study) in the classification. Finally, we used the feature vector F to do the classification; y =soft max(WcF +bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction class: [[0.2051218 0.7948782]]\n",
      "Shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "input_dim = 520  \n",
    "num_classes = 2  \n",
    "\n",
    "classification_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(input_dim,)),  \n",
    "    tf.keras.layers.Dense(\n",
    "        units=num_classes,  \n",
    "        activation='softmax' \n",
    "    )\n",
    "])\n",
    "\n",
    "#random example to see if the dimensions work\n",
    "y_pred = classification_model(concatenated_vector)\n",
    "\n",
    "print(\"Prediction class:\", y_pred.numpy()) #probability of belonging to each class\n",
    "print(\"Shape:\", y_pred.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model\n",
    "\n",
    "Example: https://www.tensorflow.org/tutorials/keras/classification?\n",
    "\n",
    "We have not trained the model, so the last prediction is randomly made.\n",
    "\n",
    "For the training of the network, the paper mentions the following:\n",
    "\n",
    "- epoch: 10\n",
    "- batch size: 16\n",
    "- learning rate: 1e-5\n",
    "- dropout: 0.2\n",
    "- max grad norm: 10\n",
    "- train: test is proportion 7:3\n",
    "- 10 consecutive runs\n",
    "- performance: accuracy\n",
    "- loss: crossentropy\n",
    "- optimizer: AdamW, where W stands for weight decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Hidden States Tensor Shape: (101, 1, 512, 768)\n",
      "Pooler Outputs Tensor Shape: (101, 1, 768)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "custom_config = BertConfig(\n",
    "    vocab_size=30522,               \n",
    "    num_attention_heads=12,        \n",
    "    num_hidden_layers=12,          \n",
    "    attention_probs_dropout_prob=0.1,  \n",
    "    hidden_size=768,               \n",
    "    intermediate_size=3072,        \n",
    "    hidden_dropout_prob=0.1,       \n",
    "    hidden_act=\"relu\",             \n",
    "    max_position_embeddings=512    \n",
    ")\n",
    "bert_model = TFBertModel(custom_config)\n",
    "\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\lclai\\\\Desktop\\\\transcripts_cleaned.csv\")\n",
    "data = data[[\"label\", \"clean_transcripts\"]]\n",
    "\n",
    "def preprocess_and_get_bert_embeddings(text, tokenizer, model, max_length=512):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"tf\",\n",
    "        padding='max_length',  \n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    \n",
    "    bert_outputs = model(**inputs)\n",
    "    return bert_outputs.last_hidden_state, bert_outputs.pooler_output \n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "last_hidden_states = []\n",
    "pooler_outputs = []\n",
    "\n",
    "for text in data['clean_transcripts']:\n",
    "    last_hidden_state, pooler_output = preprocess_and_get_bert_embeddings(text, tokenizer, bert_model)\n",
    "    last_hidden_states.append(last_hidden_state.numpy())  \n",
    "    pooler_outputs.append(pooler_output.numpy())\n",
    "\n",
    "last_hidden_states_tensor = tf.convert_to_tensor(last_hidden_states, dtype=tf.float32)\n",
    "pooler_outputs_tensor = tf.convert_to_tensor(pooler_outputs, dtype=tf.float32)\n",
    "\n",
    "print(f\"Last Hidden States Tensor Shape: {last_hidden_states_tensor.shape}\")\n",
    "print(f\"Pooler Outputs Tensor Shape: {pooler_outputs_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (70, 1, 512, 768), x test shape: (31, 1, 512, 768)\n",
      "y train shape: (70,), y test shape: (31,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = last_hidden_states_tensor.numpy()\n",
    "y = data['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "print(f\"x train shape: {X_train.shape}, x test shape: {X_test.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}, y test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_features(sample):\n",
    "    sample_with_batch_dim = tf.expand_dims(sample, axis=0)  # (1, 512, 768)\n",
    "    sample_cnn = textcnn_model(sample_with_batch_dim)  # (1, features_cnn)\n",
    "    sample_lstm = lstm_model(sample_with_batch_dim)    # (1, features_lstm)\n",
    "    concatenated_vector = tf.concat([sample_cnn, sample_lstm], axis=-1)  # (1, total_features)\n",
    "    return concatenated_vector.numpy().squeeze()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_features_train = []\n",
    "X_features_test = []\n",
    "\n",
    "for i in range(X_train.shape[0]):  \n",
    "    X_features_train.append(obtain_features(X_train[i, 0])) \n",
    "\n",
    "for i in range(X_test.shape[0]):  \n",
    "    X_features_test.append(obtain_features(X_test[i, 0]))\n",
    "\n",
    "X_features_train = np.array(X_features_train)\n",
    "X_features_test = np.array(X_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X_features_train)\n",
    "df_train['label'] = y_train\n",
    "\n",
    "df_test = pd.DataFrame(X_features_test)\n",
    "df_test['label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "      <th>513</th>\n",
       "      <th>514</th>\n",
       "      <th>515</th>\n",
       "      <th>516</th>\n",
       "      <th>517</th>\n",
       "      <th>518</th>\n",
       "      <th>519</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073820</td>\n",
       "      <td>0.271089</td>\n",
       "      <td>0.435287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355990</td>\n",
       "      <td>0.166398</td>\n",
       "      <td>...</td>\n",
       "      <td>6.962022e+04</td>\n",
       "      <td>8.955087e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126408</td>\n",
       "      <td>0.267945</td>\n",
       "      <td>0.260483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.289107</td>\n",
       "      <td>0.281003</td>\n",
       "      <td>...</td>\n",
       "      <td>3.992165e-13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.133616</td>\n",
       "      <td>2.338118e-04</td>\n",
       "      <td>1.658543e+00</td>\n",
       "      <td>3.136018e-12</td>\n",
       "      <td>1.867072e+00</td>\n",
       "      <td>1.235704e-13</td>\n",
       "      <td>7.971513e-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072878</td>\n",
       "      <td>0.227858</td>\n",
       "      <td>0.344405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361202</td>\n",
       "      <td>0.233813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.784138e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.466156e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.669911e+08</td>\n",
       "      <td>8.953333e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182789</td>\n",
       "      <td>0.241844</td>\n",
       "      <td>0.363370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285499</td>\n",
       "      <td>0.199651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.122921e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.259058e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.975562e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134997</td>\n",
       "      <td>0.222064</td>\n",
       "      <td>0.331645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346553</td>\n",
       "      <td>0.245495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>501.000610</td>\n",
       "      <td>1.242743e-16</td>\n",
       "      <td>4.236812e-24</td>\n",
       "      <td>9.075588e-11</td>\n",
       "      <td>2.013711e-18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3    4    5    6    7         8         9  \\\n",
       "0  0.0  0.073820  0.271089  0.435287  0.0  0.0  0.0  0.0  0.355990  0.166398   \n",
       "1  0.0  0.126408  0.267945  0.260483  0.0  0.0  0.0  0.0  0.289107  0.281003   \n",
       "2  0.0  0.072878  0.227858  0.344405  0.0  0.0  0.0  0.0  0.361202  0.233813   \n",
       "3  0.0  0.182789  0.241844  0.363370  0.0  0.0  0.0  0.0  0.285499  0.199651   \n",
       "4  0.0  0.134997  0.222064  0.331645  0.0  0.0  0.0  0.0  0.346553  0.245495   \n",
       "\n",
       "   ...           511           512         513           514           515  \\\n",
       "0  ...  6.962022e+04  8.955087e+03    0.000000  0.000000e+00  0.000000e+00   \n",
       "1  ...  3.992165e-13  0.000000e+00    0.133616  2.338118e-04  1.658543e+00   \n",
       "2  ...  0.000000e+00  1.784138e+09    0.000000  0.000000e+00  6.466156e+07   \n",
       "3  ...  0.000000e+00  3.122921e+04    0.000000  8.259058e+05  0.000000e+00   \n",
       "4  ...  0.000000e+00  0.000000e+00  501.000610  1.242743e-16  4.236812e-24   \n",
       "\n",
       "            516           517           518           519  label  \n",
       "0  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00      1  \n",
       "1  3.136018e-12  1.867072e+00  1.235704e-13  7.971513e-15      1  \n",
       "2  0.000000e+00  1.669911e+08  8.953333e+07  0.000000e+00      0  \n",
       "3  0.000000e+00  1.975562e+05  0.000000e+00  0.000000e+00      0  \n",
       "4  9.075588e-11  2.013711e-18  0.000000e+00  0.000000e+00      0  \n",
       "\n",
       "[5 rows x 521 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "      <th>513</th>\n",
       "      <th>514</th>\n",
       "      <th>515</th>\n",
       "      <th>516</th>\n",
       "      <th>517</th>\n",
       "      <th>518</th>\n",
       "      <th>519</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180662</td>\n",
       "      <td>0.244315</td>\n",
       "      <td>0.272865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256525</td>\n",
       "      <td>0.194838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.168127e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092131</td>\n",
       "      <td>0.260949</td>\n",
       "      <td>0.315601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339502</td>\n",
       "      <td>0.202256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.795155e+11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190818</td>\n",
       "      <td>0.209427</td>\n",
       "      <td>0.317562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307928</td>\n",
       "      <td>0.229233</td>\n",
       "      <td>...</td>\n",
       "      <td>9275.910156</td>\n",
       "      <td>2.524073e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.639098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.752287e+04</td>\n",
       "      <td>7.015045e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173291</td>\n",
       "      <td>0.207246</td>\n",
       "      <td>0.338741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331462</td>\n",
       "      <td>0.194511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.962442e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.445056e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131706</td>\n",
       "      <td>0.255530</td>\n",
       "      <td>0.342657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255869</td>\n",
       "      <td>0.207794</td>\n",
       "      <td>...</td>\n",
       "      <td>621849.312500</td>\n",
       "      <td>8.342518e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>946056.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.994316e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3    4    5    6    7         8         9  \\\n",
       "0  0.0  0.180662  0.244315  0.272865  0.0  0.0  0.0  0.0  0.256525  0.194838   \n",
       "1  0.0  0.092131  0.260949  0.315601  0.0  0.0  0.0  0.0  0.339502  0.202256   \n",
       "2  0.0  0.190818  0.209427  0.317562  0.0  0.0  0.0  0.0  0.307928  0.229233   \n",
       "3  0.0  0.173291  0.207246  0.338741  0.0  0.0  0.0  0.0  0.331462  0.194511   \n",
       "4  0.0  0.131706  0.255530  0.342657  0.0  0.0  0.0  0.0  0.255869  0.207794   \n",
       "\n",
       "   ...            511           512  513            514  515  516  \\\n",
       "0  ...       0.000000  9.168127e+04  0.0       0.000000  0.0  0.0   \n",
       "1  ...       0.000000  0.000000e+00  0.0       0.000000  0.0  0.0   \n",
       "2  ...    9275.910156  2.524073e+04  0.0      14.639098  0.0  0.0   \n",
       "3  ...       0.000000  4.962442e+07  0.0       0.000000  0.0  0.0   \n",
       "4  ...  621849.312500  8.342518e+05  0.0  946056.750000  0.0  0.0   \n",
       "\n",
       "            517           518  519  label  \n",
       "0  0.000000e+00  0.000000e+00  0.0      0  \n",
       "1  1.795155e+11  0.000000e+00  0.0      0  \n",
       "2  1.752287e+04  7.015045e+03  0.0      1  \n",
       "3  0.000000e+00  1.445056e+06  0.0      0  \n",
       "4  2.994316e+06  0.000000e+00  0.0      1  \n",
       "\n",
       "[5 rows x 521 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1674480582656.0000 - accuracy: 0.5143 - val_loss: 1036979264.0000 - val_accuracy: 0.5484\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 493911965696.0000 - accuracy: 0.4714 - val_loss: 1041800576.0000 - val_accuracy: 0.5484\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7333912510464.0000 - accuracy: 0.4857 - val_loss: 1045925888.0000 - val_accuracy: 0.5484\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6320843915264.0000 - accuracy: 0.4714 - val_loss: 1049472704.0000 - val_accuracy: 0.5484\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7455400001536.0000 - accuracy: 0.3857 - val_loss: 1052649984.0000 - val_accuracy: 0.5484\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5084058484736.0000 - accuracy: 0.4714 - val_loss: 1056350464.0000 - val_accuracy: 0.5484\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5281167179776.0000 - accuracy: 0.4429 - val_loss: 1060769344.0000 - val_accuracy: 0.5484\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2881913356288.0000 - accuracy: 0.5000 - val_loss: 1065107776.0000 - val_accuracy: 0.5484\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5532037939200.0000 - accuracy: 0.5286 - val_loss: 1069531072.0000 - val_accuracy: 0.5484\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5285195808768.0000 - accuracy: 0.4143 - val_loss: 1073734080.0000 - val_accuracy: 0.5484\n",
      "Run 2/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 902748766208.0000 - accuracy: 0.4286 - val_loss: 2459140608.0000 - val_accuracy: 0.5161\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2939146993664.0000 - accuracy: 0.4857 - val_loss: 2461661184.0000 - val_accuracy: 0.5161\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2710036283392.0000 - accuracy: 0.5429 - val_loss: 2464049408.0000 - val_accuracy: 0.5161\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2371976167424.0000 - accuracy: 0.5143 - val_loss: 2466494464.0000 - val_accuracy: 0.5161\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2660980228096.0000 - accuracy: 0.5571 - val_loss: 2469181184.0000 - val_accuracy: 0.5161\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3121026170880.0000 - accuracy: 0.5143 - val_loss: 2472356608.0000 - val_accuracy: 0.5161\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3836307046400.0000 - accuracy: 0.5571 - val_loss: 2475434496.0000 - val_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1366534258688.0000 - accuracy: 0.5714 - val_loss: 2477788672.0000 - val_accuracy: 0.5161\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1582815641600.0000 - accuracy: 0.4571 - val_loss: 2479982848.0000 - val_accuracy: 0.5161\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2081130414080.0000 - accuracy: 0.5143 - val_loss: 2482494720.0000 - val_accuracy: 0.5161\n",
      "Run 3/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 979652640768.0000 - accuracy: 0.5429 - val_loss: 1533063680.0000 - val_accuracy: 0.5484\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 336656564224.0000 - accuracy: 0.5000 - val_loss: 1537711104.0000 - val_accuracy: 0.5484\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2541596180480.0000 - accuracy: 0.5286 - val_loss: 1541468416.0000 - val_accuracy: 0.5484\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2437491720192.0000 - accuracy: 0.4571 - val_loss: 1545280768.0000 - val_accuracy: 0.5484\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4345291341824.0000 - accuracy: 0.4714 - val_loss: 1549038336.0000 - val_accuracy: 0.5484\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 697019138048.0000 - accuracy: 0.5286 - val_loss: 1553512704.0000 - val_accuracy: 0.5484\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1790593204224.0000 - accuracy: 0.4857 - val_loss: 1557473536.0000 - val_accuracy: 0.5484\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1454422491136.0000 - accuracy: 0.4714 - val_loss: 1560696064.0000 - val_accuracy: 0.5484\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 659292160000.0000 - accuracy: 0.5000 - val_loss: 1564284288.0000 - val_accuracy: 0.5484\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1376803487744.0000 - accuracy: 0.4571 - val_loss: 1568523136.0000 - val_accuracy: 0.5484\n",
      "Run 4/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 994880913408.0000 - accuracy: 0.5000 - val_loss: 21446478790656.0000 - val_accuracy: 0.7097\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 9375804416.0000 - accuracy: 0.4571 - val_loss: 21378784821248.0000 - val_accuracy: 0.7097\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3030844928.0000 - accuracy: 0.5429 - val_loss: 21322302226432.0000 - val_accuracy: 0.7097\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1050269777920.0000 - accuracy: 0.4857 - val_loss: 21281074315264.0000 - val_accuracy: 0.7097\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1112808620032.0000 - accuracy: 0.4714 - val_loss: 21275149860864.0000 - val_accuracy: 0.7097\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 101640200192.0000 - accuracy: 0.5143 - val_loss: 21268982136832.0000 - val_accuracy: 0.7097\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 83825827840.0000 - accuracy: 0.5000 - val_loss: 21259811291136.0000 - val_accuracy: 0.7097\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1973279522816.0000 - accuracy: 0.5143 - val_loss: 21241608011776.0000 - val_accuracy: 0.7097\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 187736784896.0000 - accuracy: 0.5571 - val_loss: 21206822551552.0000 - val_accuracy: 0.7097\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 60822458368.0000 - accuracy: 0.4714 - val_loss: 21156356685824.0000 - val_accuracy: 0.7097\n",
      "Run 5/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 30ms/step - loss: 3215047524352.0000 - accuracy: 0.3857 - val_loss: 15256623513600.0000 - val_accuracy: 0.3548\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1964229656576.0000 - accuracy: 0.4714 - val_loss: 15191578247168.0000 - val_accuracy: 0.3548\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 167865401344.0000 - accuracy: 0.4714 - val_loss: 15120278224896.0000 - val_accuracy: 0.3548\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 895749324800.0000 - accuracy: 0.4286 - val_loss: 15056644341760.0000 - val_accuracy: 0.3548\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 210089066496.0000 - accuracy: 0.4429 - val_loss: 15021140606976.0000 - val_accuracy: 0.3548\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 325059739648.0000 - accuracy: 0.5000 - val_loss: 14988574982144.0000 - val_accuracy: 0.3548\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 614905675776.0000 - accuracy: 0.5000 - val_loss: 14949332025344.0000 - val_accuracy: 0.3548\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1639704297472.0000 - accuracy: 0.4143 - val_loss: 14918012108800.0000 - val_accuracy: 0.3548\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 164814307328.0000 - accuracy: 0.4286 - val_loss: 14887771176960.0000 - val_accuracy: 0.3548\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 95883509760.0000 - accuracy: 0.5286 - val_loss: 14844922167296.0000 - val_accuracy: 0.3548\n",
      "Run 6/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5266495504384.0000 - accuracy: 0.4143 - val_loss: 1117965.2500 - val_accuracy: 0.5484\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1891902423040.0000 - accuracy: 0.4429 - val_loss: 1119813.1250 - val_accuracy: 0.5484\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7860706082816.0000 - accuracy: 0.4000 - val_loss: 1121432.8750 - val_accuracy: 0.5484\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7523571073024.0000 - accuracy: 0.4857 - val_loss: 1122761.5000 - val_accuracy: 0.5484\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6515533545472.0000 - accuracy: 0.4000 - val_loss: 1124146.1250 - val_accuracy: 0.5484\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7877483298816.0000 - accuracy: 0.4571 - val_loss: 1125545.2500 - val_accuracy: 0.5484\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6913920073728.0000 - accuracy: 0.4429 - val_loss: 1126666.3750 - val_accuracy: 0.5484\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 661504065536.0000 - accuracy: 0.4143 - val_loss: 1127795.0000 - val_accuracy: 0.5484\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 9093669453824.0000 - accuracy: 0.4286 - val_loss: 1129081.3750 - val_accuracy: 0.5484\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7856437329920.0000 - accuracy: 0.4571 - val_loss: 1130624.1250 - val_accuracy: 0.5484\n",
      "Run 7/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2712864817152.0000 - accuracy: 0.4714 - val_loss: 1421652736.0000 - val_accuracy: 0.5161\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2647099179008.0000 - accuracy: 0.4143 - val_loss: 1423303936.0000 - val_accuracy: 0.5161\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2037077639168.0000 - accuracy: 0.4143 - val_loss: 1424193408.0000 - val_accuracy: 0.5161\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1926574899200.0000 - accuracy: 0.4286 - val_loss: 1425014912.0000 - val_accuracy: 0.5161\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1866134585344.0000 - accuracy: 0.4143 - val_loss: 1425721216.0000 - val_accuracy: 0.5161\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2717238165504.0000 - accuracy: 0.4571 - val_loss: 1425942016.0000 - val_accuracy: 0.5161\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2627305472000.0000 - accuracy: 0.4714 - val_loss: 1426914176.0000 - val_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1932975931392.0000 - accuracy: 0.4571 - val_loss: 1427955328.0000 - val_accuracy: 0.5161\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1758923456512.0000 - accuracy: 0.4286 - val_loss: 1429606400.0000 - val_accuracy: 0.5161\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1600023822336.0000 - accuracy: 0.4429 - val_loss: 1431880320.0000 - val_accuracy: 0.5161\n",
      "Run 8/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1036999720960.0000 - accuracy: 0.4143 - val_loss: 1194214016.0000 - val_accuracy: 0.4839\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 37205422080.0000 - accuracy: 0.3714 - val_loss: 1197499904.0000 - val_accuracy: 0.4839\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4918419652608.0000 - accuracy: 0.3286 - val_loss: 1200709632.0000 - val_accuracy: 0.4839\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5163261100032.0000 - accuracy: 0.4286 - val_loss: 1203512576.0000 - val_accuracy: 0.4516\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 5491106775040.0000 - accuracy: 0.3571 - val_loss: 1206733568.0000 - val_accuracy: 0.4516\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3863536992256.0000 - accuracy: 0.3857 - val_loss: 1210377984.0000 - val_accuracy: 0.4516\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4595543703552.0000 - accuracy: 0.5000 - val_loss: 1214553472.0000 - val_accuracy: 0.4516\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 317164879872.0000 - accuracy: 0.4000 - val_loss: 1218407680.0000 - val_accuracy: 0.4516\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6848968130560.0000 - accuracy: 0.4143 - val_loss: 1222665984.0000 - val_accuracy: 0.4516\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4997990842368.0000 - accuracy: 0.4143 - val_loss: 1227210496.0000 - val_accuracy: 0.4516\n",
      "Run 9/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2682960478208.0000 - accuracy: 0.4571 - val_loss: 2795904512.0000 - val_accuracy: 0.5161\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1680669147136.0000 - accuracy: 0.4429 - val_loss: 2796256512.0000 - val_accuracy: 0.5161\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3233802354688.0000 - accuracy: 0.4714 - val_loss: 2796701952.0000 - val_accuracy: 0.5161\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2887098826752.0000 - accuracy: 0.4571 - val_loss: 2797038336.0000 - val_accuracy: 0.5161\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3016070004736.0000 - accuracy: 0.4714 - val_loss: 2797005824.0000 - val_accuracy: 0.5161\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2373801213952.0000 - accuracy: 0.4286 - val_loss: 2797384704.0000 - val_accuracy: 0.5161\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2891692638208.0000 - accuracy: 0.4429 - val_loss: 2798440960.0000 - val_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2326980722688.0000 - accuracy: 0.4286 - val_loss: 2801365248.0000 - val_accuracy: 0.5161\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2079745900544.0000 - accuracy: 0.4143 - val_loss: 2805557760.0000 - val_accuracy: 0.5161\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2107419131904.0000 - accuracy: 0.4000 - val_loss: 2809666560.0000 - val_accuracy: 0.5161\n",
      "Run 10/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 311801085952.0000 - accuracy: 0.5571 - val_loss: 46926103838720.0000 - val_accuracy: 0.2903\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 653705019392.0000 - accuracy: 0.5143 - val_loss: 46854406406144.0000 - val_accuracy: 0.2903\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 26676725760.0000 - accuracy: 0.5857 - val_loss: 46800920641536.0000 - val_accuracy: 0.2903\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 176961667072.0000 - accuracy: 0.5000 - val_loss: 46750345723904.0000 - val_accuracy: 0.2903\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 123060420608.0000 - accuracy: 0.5429 - val_loss: 46720083820544.0000 - val_accuracy: 0.2903\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 146327699456.0000 - accuracy: 0.6143 - val_loss: 46689121468416.0000 - val_accuracy: 0.2903\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 118367363072.0000 - accuracy: 0.6571 - val_loss: 46669991247872.0000 - val_accuracy: 0.2903\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1256080277504.0000 - accuracy: 0.5714 - val_loss: 46648659017728.0000 - val_accuracy: 0.2903\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 393243656192.0000 - accuracy: 0.5714 - val_loss: 46626471149568.0000 - val_accuracy: 0.2903\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 102523953152.0000 - accuracy: 0.6857 - val_loss: 46590551130112.0000 - val_accuracy: 0.2903\n",
      "Run 11/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1104279764992.0000 - accuracy: 0.4857 - val_loss: 6178961408.0000 - val_accuracy: 0.4516\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1110506864640.0000 - accuracy: 0.5000 - val_loss: 6177364480.0000 - val_accuracy: 0.4516\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 809457287168.0000 - accuracy: 0.5429 - val_loss: 6174380032.0000 - val_accuracy: 0.4516\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1013540388864.0000 - accuracy: 0.5286 - val_loss: 6171946496.0000 - val_accuracy: 0.4516\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1202769494016.0000 - accuracy: 0.5143 - val_loss: 6169265152.0000 - val_accuracy: 0.4516\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1111709319168.0000 - accuracy: 0.5143 - val_loss: 6166527488.0000 - val_accuracy: 0.4516\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1122599436288.0000 - accuracy: 0.4429 - val_loss: 6163966464.0000 - val_accuracy: 0.4516\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1116167340032.0000 - accuracy: 0.4857 - val_loss: 6161025024.0000 - val_accuracy: 0.4516\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1023771213824.0000 - accuracy: 0.4857 - val_loss: 6159224320.0000 - val_accuracy: 0.4516\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 352437862400.0000 - accuracy: 0.5000 - val_loss: 6157179904.0000 - val_accuracy: 0.4516\n",
      "Run 12/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9543505920.0000 - accuracy: 0.4429 - val_loss: 22406122962944.0000 - val_accuracy: 0.5484\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 94490124288.0000 - accuracy: 0.4429 - val_loss: 22360830771200.0000 - val_accuracy: 0.5484\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 628423936.0000 - accuracy: 0.5571 - val_loss: 22347050385408.0000 - val_accuracy: 0.5484\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 170165731328.0000 - accuracy: 0.5286 - val_loss: 22345951477760.0000 - val_accuracy: 0.5484\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 176954310656.0000 - accuracy: 0.4714 - val_loss: 22376926412800.0000 - val_accuracy: 0.5484\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 128737452032.0000 - accuracy: 0.4857 - val_loss: 22399619694592.0000 - val_accuracy: 0.5484\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 179383484416.0000 - accuracy: 0.5143 - val_loss: 22423671930880.0000 - val_accuracy: 0.5484\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 80658235392.0000 - accuracy: 0.4857 - val_loss: 22462337122304.0000 - val_accuracy: 0.5484\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 129838664.0000 - accuracy: 0.5000 - val_loss: 22485806350336.0000 - val_accuracy: 0.5484\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 639905038336.0000 - accuracy: 0.4429 - val_loss: 22472768356352.0000 - val_accuracy: 0.5484\n",
      "Run 13/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 255162793984.0000 - accuracy: 0.5571 - val_loss: 3457219328.0000 - val_accuracy: 0.4516\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 114567462912.0000 - accuracy: 0.5429 - val_loss: 3454364672.0000 - val_accuracy: 0.4516\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 214909829120.0000 - accuracy: 0.4714 - val_loss: 3452159488.0000 - val_accuracy: 0.4516\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 207224438784.0000 - accuracy: 0.5143 - val_loss: 3450044416.0000 - val_accuracy: 0.4516\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 628411006976.0000 - accuracy: 0.4571 - val_loss: 3447494400.0000 - val_accuracy: 0.4516\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 57176793088.0000 - accuracy: 0.5286 - val_loss: 3445631744.0000 - val_accuracy: 0.4516\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 370827329536.0000 - accuracy: 0.5857 - val_loss: 3444430080.0000 - val_accuracy: 0.4516\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 143920201728.0000 - accuracy: 0.5571 - val_loss: 3442241280.0000 - val_accuracy: 0.4516\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 298380984320.0000 - accuracy: 0.5429 - val_loss: 3440459264.0000 - val_accuracy: 0.4516\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 195117793280.0000 - accuracy: 0.5000 - val_loss: 3439112960.0000 - val_accuracy: 0.4516\n",
      "Run 14/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 754508496896.0000 - accuracy: 0.5143 - val_loss: 66904018386944.0000 - val_accuracy: 0.3226\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2613105131520.0000 - accuracy: 0.5000 - val_loss: 66848703905792.0000 - val_accuracy: 0.3226\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 568748802048.0000 - accuracy: 0.5857 - val_loss: 66811580121088.0000 - val_accuracy: 0.3226\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 475141341184.0000 - accuracy: 0.6000 - val_loss: 66781246914560.0000 - val_accuracy: 0.3226\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 279864868864.0000 - accuracy: 0.5857 - val_loss: 66775270031360.0000 - val_accuracy: 0.3226\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1355687657472.0000 - accuracy: 0.4714 - val_loss: 66752511737856.0000 - val_accuracy: 0.3226\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1169430151168.0000 - accuracy: 0.5000 - val_loss: 66737600987136.0000 - val_accuracy: 0.3226\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 332334891008.0000 - accuracy: 0.5857 - val_loss: 66732517490688.0000 - val_accuracy: 0.3226\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 451535470592.0000 - accuracy: 0.5000 - val_loss: 66724326014976.0000 - val_accuracy: 0.3226\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3535763712.0000 - accuracy: 0.5714 - val_loss: 66715085963264.0000 - val_accuracy: 0.3226\n",
      "Run 15/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 947289980928.0000 - accuracy: 0.5286 - val_loss: 6630088376320.0000 - val_accuracy: 0.5161\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2572978487296.0000 - accuracy: 0.5714 - val_loss: 6607999598592.0000 - val_accuracy: 0.5161\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1538393767936.0000 - accuracy: 0.6286 - val_loss: 6607439659008.0000 - val_accuracy: 0.5161\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 460958269440.0000 - accuracy: 0.5571 - val_loss: 6582473588736.0000 - val_accuracy: 0.5161\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 516056514560.0000 - accuracy: 0.6000 - val_loss: 6566733938688.0000 - val_accuracy: 0.5161\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1949403709440.0000 - accuracy: 0.5286 - val_loss: 6549806252032.0000 - val_accuracy: 0.5161\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2090467983360.0000 - accuracy: 0.5714 - val_loss: 6526555127808.0000 - val_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1193712287744.0000 - accuracy: 0.6143 - val_loss: 6528319881216.0000 - val_accuracy: 0.5161\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 261230149632.0000 - accuracy: 0.6000 - val_loss: 6537581953024.0000 - val_accuracy: 0.5161\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1482666147840.0000 - accuracy: 0.6000 - val_loss: 6529400963072.0000 - val_accuracy: 0.5161\n",
      "Run 16/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5162623041536.0000 - accuracy: 0.4714 - val_loss: 4974893568.0000 - val_accuracy: 0.5806\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2408351531008.0000 - accuracy: 0.5000 - val_loss: 4980202496.0000 - val_accuracy: 0.5806\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 6633601630208.0000 - accuracy: 0.5000 - val_loss: 4984740864.0000 - val_accuracy: 0.5806\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6951513620480.0000 - accuracy: 0.4714 - val_loss: 4988999680.0000 - val_accuracy: 0.5806\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6977963425792.0000 - accuracy: 0.4571 - val_loss: 4993537536.0000 - val_accuracy: 0.5806\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7148495437824.0000 - accuracy: 0.4857 - val_loss: 4998583808.0000 - val_accuracy: 0.5806\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 6997345828864.0000 - accuracy: 0.5429 - val_loss: 5002922496.0000 - val_accuracy: 0.5806\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3035451359232.0000 - accuracy: 0.4286 - val_loss: 5007165440.0000 - val_accuracy: 0.5806\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7379213090816.0000 - accuracy: 0.4143 - val_loss: 5010888704.0000 - val_accuracy: 0.5806\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7346634358784.0000 - accuracy: 0.4571 - val_loss: 5013895168.0000 - val_accuracy: 0.5806\n",
      "Run 17/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6171390377984.0000 - accuracy: 0.4143 - val_loss: 56279980572672.0000 - val_accuracy: 0.5161\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3117109215232.0000 - accuracy: 0.3857 - val_loss: 56182530113536.0000 - val_accuracy: 0.5161\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 8055537270784.0000 - accuracy: 0.3714 - val_loss: 56093006888960.0000 - val_accuracy: 0.5161\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7061056258048.0000 - accuracy: 0.4571 - val_loss: 56008814624768.0000 - val_accuracy: 0.5161\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6086415351808.0000 - accuracy: 0.4857 - val_loss: 55927289937920.0000 - val_accuracy: 0.5161\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7092315357184.0000 - accuracy: 0.4286 - val_loss: 55840342016000.0000 - val_accuracy: 0.5161\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5753787645952.0000 - accuracy: 0.4286 - val_loss: 55754765631488.0000 - val_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3542305210368.0000 - accuracy: 0.3429 - val_loss: 55675522646016.0000 - val_accuracy: 0.5161\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6757325733888.0000 - accuracy: 0.4286 - val_loss: 55597923827712.0000 - val_accuracy: 0.5161\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7418848739328.0000 - accuracy: 0.4000 - val_loss: 55520970932224.0000 - val_accuracy: 0.5161\n",
      "Run 18/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1045168324608.0000 - accuracy: 0.4857 - val_loss: 61195600003072.0000 - val_accuracy: 0.6129\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1293027770368.0000 - accuracy: 0.5286 - val_loss: 61178017480704.0000 - val_accuracy: 0.6129\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1521241423872.0000 - accuracy: 0.4714 - val_loss: 61175337320448.0000 - val_accuracy: 0.6129\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1047590010880.0000 - accuracy: 0.5286 - val_loss: 61170031525888.0000 - val_accuracy: 0.6129\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1338623524864.0000 - accuracy: 0.5429 - val_loss: 61187727294464.0000 - val_accuracy: 0.6129\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1300164640768.0000 - accuracy: 0.4714 - val_loss: 61192521383936.0000 - val_accuracy: 0.6129\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1259112366080.0000 - accuracy: 0.5286 - val_loss: 61185982464000.0000 - val_accuracy: 0.6129\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1730865528832.0000 - accuracy: 0.4714 - val_loss: 61172330004480.0000 - val_accuracy: 0.6129\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 487368359936.0000 - accuracy: 0.6143 - val_loss: 61152268648448.0000 - val_accuracy: 0.6129\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 684117852160.0000 - accuracy: 0.5143 - val_loss: 61137244651520.0000 - val_accuracy: 0.6129\n",
      "Run 19/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1114776403968.0000 - accuracy: 0.6857 - val_loss: 86051917922304.0000 - val_accuracy: 0.5806\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1112825528320.0000 - accuracy: 0.5429 - val_loss: 85953712488448.0000 - val_accuracy: 0.5806\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2835715719168.0000 - accuracy: 0.5429 - val_loss: 85862217940992.0000 - val_accuracy: 0.5806\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3353043009536.0000 - accuracy: 0.6000 - val_loss: 85773541965824.0000 - val_accuracy: 0.5806\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3406741110784.0000 - accuracy: 0.5286 - val_loss: 85691618820096.0000 - val_accuracy: 0.5806\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2147442229248.0000 - accuracy: 0.5857 - val_loss: 85607053262848.0000 - val_accuracy: 0.5806\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 915749863424.0000 - accuracy: 0.5429 - val_loss: 85525868314624.0000 - val_accuracy: 0.5806\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3081989783552.0000 - accuracy: 0.6571 - val_loss: 85444406542336.0000 - val_accuracy: 0.5806\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3538811092992.0000 - accuracy: 0.6143 - val_loss: 85369253003264.0000 - val_accuracy: 0.5806\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1882294583296.0000 - accuracy: 0.6286 - val_loss: 85287858339840.0000 - val_accuracy: 0.5806\n",
      "Run 20/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 506066698240.0000 - accuracy: 0.5143 - val_loss: 260012032.0000 - val_accuracy: 0.3871\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 573652008960.0000 - accuracy: 0.5143 - val_loss: 260182416.0000 - val_accuracy: 0.3871\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 468644790272.0000 - accuracy: 0.5143 - val_loss: 260201776.0000 - val_accuracy: 0.3871\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 556087771136.0000 - accuracy: 0.5571 - val_loss: 260304624.0000 - val_accuracy: 0.3871\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 481226063872.0000 - accuracy: 0.4714 - val_loss: 259936976.0000 - val_accuracy: 0.3871\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 478919688192.0000 - accuracy: 0.5714 - val_loss: 259623568.0000 - val_accuracy: 0.3871\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 277854486528.0000 - accuracy: 0.5286 - val_loss: 259371952.0000 - val_accuracy: 0.3871\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 419548364800.0000 - accuracy: 0.6000 - val_loss: 258843664.0000 - val_accuracy: 0.3871\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 496100081664.0000 - accuracy: 0.4857 - val_loss: 258574512.0000 - val_accuracy: 0.3871\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 373914501120.0000 - accuracy: 0.5286 - val_loss: 258431104.0000 - val_accuracy: 0.3871\n",
      "Run 21/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3680532430848.0000 - accuracy: 0.4857 - val_loss: 42742356901888.0000 - val_accuracy: 0.3548\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3422845665280.0000 - accuracy: 0.5143 - val_loss: 42700040568832.0000 - val_accuracy: 0.3871\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1554261082112.0000 - accuracy: 0.6000 - val_loss: 42665307537408.0000 - val_accuracy: 0.3871\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1315764305920.0000 - accuracy: 0.4857 - val_loss: 42617337282560.0000 - val_accuracy: 0.3871\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 568975884288.0000 - accuracy: 0.6143 - val_loss: 42587905851392.0000 - val_accuracy: 0.3871\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2366668013568.0000 - accuracy: 0.5286 - val_loss: 42559598493696.0000 - val_accuracy: 0.3871\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1672363507712.0000 - accuracy: 0.5571 - val_loss: 42517860974592.0000 - val_accuracy: 0.3871\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2361769852928.0000 - accuracy: 0.5571 - val_loss: 42493856972800.0000 - val_accuracy: 0.3871\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1011897270272.0000 - accuracy: 0.5143 - val_loss: 42464626868224.0000 - val_accuracy: 0.3871\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1288103264256.0000 - accuracy: 0.5571 - val_loss: 42431764496384.0000 - val_accuracy: 0.3871\n",
      "Run 22/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1906190712832.0000 - accuracy: 0.5571 - val_loss: 1183926452224.0000 - val_accuracy: 0.4516\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1821950214144.0000 - accuracy: 0.5714 - val_loss: 1083363426304.0000 - val_accuracy: 0.4516\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5025472446464.0000 - accuracy: 0.4714 - val_loss: 998287474688.0000 - val_accuracy: 0.4516\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4204392873984.0000 - accuracy: 0.5000 - val_loss: 913651204096.0000 - val_accuracy: 0.4516\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3630496481280.0000 - accuracy: 0.5571 - val_loss: 835251404800.0000 - val_accuracy: 0.4516\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4201621225472.0000 - accuracy: 0.5571 - val_loss: 754463670272.0000 - val_accuracy: 0.4516\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4448384450560.0000 - accuracy: 0.5143 - val_loss: 667926593536.0000 - val_accuracy: 0.4516\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3018420912128.0000 - accuracy: 0.5143 - val_loss: 582183944192.0000 - val_accuracy: 0.4516\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4721517527040.0000 - accuracy: 0.5286 - val_loss: 501388148736.0000 - val_accuracy: 0.4516\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5392195649536.0000 - accuracy: 0.4857 - val_loss: 413539303424.0000 - val_accuracy: 0.4516\n",
      "Run 23/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3593999745024.0000 - accuracy: 0.4714 - val_loss: 349966144.0000 - val_accuracy: 0.5161\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3693113245696.0000 - accuracy: 0.5143 - val_loss: 355452480.0000 - val_accuracy: 0.5161\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 6680268505088.0000 - accuracy: 0.4143 - val_loss: 359720992.0000 - val_accuracy: 0.5161\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6604238356480.0000 - accuracy: 0.4429 - val_loss: 363559136.0000 - val_accuracy: 0.5161\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6057009610752.0000 - accuracy: 0.5000 - val_loss: 366767360.0000 - val_accuracy: 0.5161\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5647796535296.0000 - accuracy: 0.4714 - val_loss: 370377152.0000 - val_accuracy: 0.5161\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4223117557760.0000 - accuracy: 0.4143 - val_loss: 374375840.0000 - val_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 532425539584.0000 - accuracy: 0.4857 - val_loss: 377789312.0000 - val_accuracy: 0.5161\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6442923851776.0000 - accuracy: 0.4429 - val_loss: 381509152.0000 - val_accuracy: 0.5161\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7361938849792.0000 - accuracy: 0.4571 - val_loss: 385173120.0000 - val_accuracy: 0.5161\n",
      "Run 24/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 39ms/step - loss: 1769051258880.0000 - accuracy: 0.4286 - val_loss: 985592576.0000 - val_accuracy: 0.5806\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1219976101888.0000 - accuracy: 0.5000 - val_loss: 986871616.0000 - val_accuracy: 0.5806\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2246906478592.0000 - accuracy: 0.4286 - val_loss: 988188864.0000 - val_accuracy: 0.5806\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1619662733312.0000 - accuracy: 0.4714 - val_loss: 989414528.0000 - val_accuracy: 0.5806\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3448610488320.0000 - accuracy: 0.4429 - val_loss: 990564224.0000 - val_accuracy: 0.5806\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2081294385152.0000 - accuracy: 0.4429 - val_loss: 991789312.0000 - val_accuracy: 0.5806\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2549263368192.0000 - accuracy: 0.4429 - val_loss: 993419648.0000 - val_accuracy: 0.5806\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1246136762368.0000 - accuracy: 0.4143 - val_loss: 994699968.0000 - val_accuracy: 0.5806\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 539148582912.0000 - accuracy: 0.5000 - val_loss: 995882944.0000 - val_accuracy: 0.5806\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2229078065152.0000 - accuracy: 0.4429 - val_loss: 996715072.0000 - val_accuracy: 0.5806\n",
      "Run 25/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 53ms/step - loss: 5198515798016.0000 - accuracy: 0.5286 - val_loss: 17591749836800.0000 - val_accuracy: 0.5806\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1982884741120.0000 - accuracy: 0.5143 - val_loss: 17502513922048.0000 - val_accuracy: 0.5806\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3086676393984.0000 - accuracy: 0.5000 - val_loss: 17424555442176.0000 - val_accuracy: 0.5806\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3250209161216.0000 - accuracy: 0.4857 - val_loss: 17358753103872.0000 - val_accuracy: 0.5806\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1024746586112.0000 - accuracy: 0.5429 - val_loss: 17294560329728.0000 - val_accuracy: 0.5806\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4822557261824.0000 - accuracy: 0.4857 - val_loss: 17221479825408.0000 - val_accuracy: 0.5806\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1658697547776.0000 - accuracy: 0.4857 - val_loss: 17148351086592.0000 - val_accuracy: 0.5806\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2627922558976.0000 - accuracy: 0.5000 - val_loss: 17079305502720.0000 - val_accuracy: 0.5806\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2754940502016.0000 - accuracy: 0.5429 - val_loss: 17008640917504.0000 - val_accuracy: 0.5806\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3139071639552.0000 - accuracy: 0.5000 - val_loss: 16935931609088.0000 - val_accuracy: 0.5806\n",
      "Run 26/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 49ms/step - loss: 885385789440.0000 - accuracy: 0.5286 - val_loss: 2634503936.0000 - val_accuracy: 0.4839\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1221752258560.0000 - accuracy: 0.5714 - val_loss: 2633957888.0000 - val_accuracy: 0.4839\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1200624893952.0000 - accuracy: 0.5000 - val_loss: 2633706240.0000 - val_accuracy: 0.4839\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 810229628928.0000 - accuracy: 0.5714 - val_loss: 2633380352.0000 - val_accuracy: 0.4839\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 406478487552.0000 - accuracy: 0.5286 - val_loss: 2632571904.0000 - val_accuracy: 0.4839\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1487941926912.0000 - accuracy: 0.5714 - val_loss: 2632121088.0000 - val_accuracy: 0.4839\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1244898000896.0000 - accuracy: 0.5286 - val_loss: 2631665920.0000 - val_accuracy: 0.4839\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1269313961984.0000 - accuracy: 0.5857 - val_loss: 2631117312.0000 - val_accuracy: 0.4839\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 745856172032.0000 - accuracy: 0.5143 - val_loss: 2631157248.0000 - val_accuracy: 0.4839\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1730642968576.0000 - accuracy: 0.5429 - val_loss: 2631813376.0000 - val_accuracy: 0.4839\n",
      "Run 27/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 42ms/step - loss: 427592581120.0000 - accuracy: 0.6000 - val_loss: 31377948934144.0000 - val_accuracy: 0.4839\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 403273351168.0000 - accuracy: 0.6286 - val_loss: 31372926255104.0000 - val_accuracy: 0.4839\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 575629164544.0000 - accuracy: 0.5857 - val_loss: 31369828761600.0000 - val_accuracy: 0.4839\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 431809396736.0000 - accuracy: 0.5857 - val_loss: 31362037841920.0000 - val_accuracy: 0.4839\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 364819808256.0000 - accuracy: 0.5857 - val_loss: 31380188692480.0000 - val_accuracy: 0.4839\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 591244099584.0000 - accuracy: 0.6286 - val_loss: 31400719810560.0000 - val_accuracy: 0.4839\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 612331749376.0000 - accuracy: 0.5857 - val_loss: 31404052185088.0000 - val_accuracy: 0.4839\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 689437147136.0000 - accuracy: 0.6143 - val_loss: 31419233468416.0000 - val_accuracy: 0.4839\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 269540212736.0000 - accuracy: 0.5714 - val_loss: 31433842229248.0000 - val_accuracy: 0.4839\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 487483015168.0000 - accuracy: 0.6000 - val_loss: 31430572769280.0000 - val_accuracy: 0.4839\n",
      "Run 28/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 46ms/step - loss: 2698551230464.0000 - accuracy: 0.5000 - val_loss: 35166328193024.0000 - val_accuracy: 0.5484\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2363416117248.0000 - accuracy: 0.4286 - val_loss: 35076123394048.0000 - val_accuracy: 0.5484\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3470414315520.0000 - accuracy: 0.4857 - val_loss: 34990008041472.0000 - val_accuracy: 0.5484\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3750362873856.0000 - accuracy: 0.5143 - val_loss: 34911369035776.0000 - val_accuracy: 0.5484\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2454170107904.0000 - accuracy: 0.5286 - val_loss: 34836500709376.0000 - val_accuracy: 0.5484\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4017946886144.0000 - accuracy: 0.5286 - val_loss: 34753692565504.0000 - val_accuracy: 0.5484\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2877316923392.0000 - accuracy: 0.4286 - val_loss: 34671809265664.0000 - val_accuracy: 0.5484\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 234552180736.0000 - accuracy: 0.6000 - val_loss: 34598037749760.0000 - val_accuracy: 0.5484\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3844254728192.0000 - accuracy: 0.5143 - val_loss: 34527160303616.0000 - val_accuracy: 0.5484\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3721014804480.0000 - accuracy: 0.5286 - val_loss: 34448502423552.0000 - val_accuracy: 0.5484\n",
      "Run 29/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 47ms/step - loss: 1983055659008.0000 - accuracy: 0.5714 - val_loss: 1876577152.0000 - val_accuracy: 0.3548\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3454570070016.0000 - accuracy: 0.5286 - val_loss: 1881324928.0000 - val_accuracy: 0.3548\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3355859746816.0000 - accuracy: 0.5857 - val_loss: 1885970816.0000 - val_accuracy: 0.3548\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3053408223232.0000 - accuracy: 0.5286 - val_loss: 1889818880.0000 - val_accuracy: 0.3548\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3059580141568.0000 - accuracy: 0.5571 - val_loss: 1892971008.0000 - val_accuracy: 0.3548\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2946807627776.0000 - accuracy: 0.6000 - val_loss: 1896205440.0000 - val_accuracy: 0.3548\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3706036682752.0000 - accuracy: 0.6000 - val_loss: 1900065920.0000 - val_accuracy: 0.3548\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 267581489152.0000 - accuracy: 0.5714 - val_loss: 1903743872.0000 - val_accuracy: 0.3548\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3749602656256.0000 - accuracy: 0.5143 - val_loss: 1908541056.0000 - val_accuracy: 0.3548\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2954127474688.0000 - accuracy: 0.5857 - val_loss: 1912774144.0000 - val_accuracy: 0.3548\n",
      "Run 30/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2113955299328.0000 - accuracy: 0.4857 - val_loss: 2804497776640.0000 - val_accuracy: 0.6452\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2429048586240.0000 - accuracy: 0.5143 - val_loss: 2777848217600.0000 - val_accuracy: 0.6452\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4214152495104.0000 - accuracy: 0.4857 - val_loss: 2734316847104.0000 - val_accuracy: 0.6452\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3276237963264.0000 - accuracy: 0.5286 - val_loss: 2686629183488.0000 - val_accuracy: 0.6452\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3335872839680.0000 - accuracy: 0.5000 - val_loss: 2651306590208.0000 - val_accuracy: 0.6452\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4206329331712.0000 - accuracy: 0.4286 - val_loss: 2598216925184.0000 - val_accuracy: 0.6452\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3619022962688.0000 - accuracy: 0.5286 - val_loss: 2541378338816.0000 - val_accuracy: 0.6452\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4005183881216.0000 - accuracy: 0.4714 - val_loss: 2511750037504.0000 - val_accuracy: 0.6452\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3961960529920.0000 - accuracy: 0.5286 - val_loss: 2480007544832.0000 - val_accuracy: 0.6452\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4329591537664.0000 - accuracy: 0.5429 - val_loss: 2424540758016.0000 - val_accuracy: 0.6452\n",
      "Run 31/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 2603559944192.0000 - accuracy: 0.4429 - val_loss: 33707536678912.0000 - val_accuracy: 0.4516\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4402102403072.0000 - accuracy: 0.4857 - val_loss: 33646434058240.0000 - val_accuracy: 0.4516\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3275405918208.0000 - accuracy: 0.5143 - val_loss: 33595299201024.0000 - val_accuracy: 0.4516\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3239203307520.0000 - accuracy: 0.5143 - val_loss: 33547503009792.0000 - val_accuracy: 0.4516\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3587800301568.0000 - accuracy: 0.5429 - val_loss: 33500646342656.0000 - val_accuracy: 0.4516\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3401609641984.0000 - accuracy: 0.4286 - val_loss: 33443555573760.0000 - val_accuracy: 0.4516\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3958890561536.0000 - accuracy: 0.4429 - val_loss: 33384873066496.0000 - val_accuracy: 0.4516\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 397786644480.0000 - accuracy: 0.4571 - val_loss: 33336187682816.0000 - val_accuracy: 0.4516\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2248104214528.0000 - accuracy: 0.4714 - val_loss: 33286160121856.0000 - val_accuracy: 0.4516\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2924432064512.0000 - accuracy: 0.5714 - val_loss: 33242566623232.0000 - val_accuracy: 0.4516\n",
      "Run 32/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 32ms/step - loss: 613776162816.0000 - accuracy: 0.5857 - val_loss: 1273608704.0000 - val_accuracy: 0.3871\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 861519937536.0000 - accuracy: 0.5571 - val_loss: 1277718272.0000 - val_accuracy: 0.3871\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3656937635840.0000 - accuracy: 0.6000 - val_loss: 1281650304.0000 - val_accuracy: 0.3871\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3497024815104.0000 - accuracy: 0.5714 - val_loss: 1284850304.0000 - val_accuracy: 0.3871\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3762469470208.0000 - accuracy: 0.5429 - val_loss: 1287505152.0000 - val_accuracy: 0.3871\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2387544375296.0000 - accuracy: 0.5857 - val_loss: 1290321152.0000 - val_accuracy: 0.3871\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1958750715904.0000 - accuracy: 0.4857 - val_loss: 1293029888.0000 - val_accuracy: 0.3871\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 58723532800.0000 - accuracy: 0.6000 - val_loss: 1295270656.0000 - val_accuracy: 0.3871\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4346159824896.0000 - accuracy: 0.6000 - val_loss: 1297687424.0000 - val_accuracy: 0.3871\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 3752239824896.0000 - accuracy: 0.5714 - val_loss: 1300541696.0000 - val_accuracy: 0.3871\n",
      "Run 33/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1926696534016.0000 - accuracy: 0.4857 - val_loss: 41361168400384.0000 - val_accuracy: 0.6452\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 960606437376.0000 - accuracy: 0.5857 - val_loss: 41264875569152.0000 - val_accuracy: 0.6452\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4318982307840.0000 - accuracy: 0.5571 - val_loss: 41174719004672.0000 - val_accuracy: 0.6452\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4636129361920.0000 - accuracy: 0.5714 - val_loss: 41095329218560.0000 - val_accuracy: 0.6452\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6539493507072.0000 - accuracy: 0.4857 - val_loss: 41019773026304.0000 - val_accuracy: 0.6452\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3566257045504.0000 - accuracy: 0.5429 - val_loss: 40934712541184.0000 - val_accuracy: 0.6452\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5488331718656.0000 - accuracy: 0.5714 - val_loss: 40851459801088.0000 - val_accuracy: 0.6452\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1288792702976.0000 - accuracy: 0.5143 - val_loss: 40770224521216.0000 - val_accuracy: 0.6452\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3923187073024.0000 - accuracy: 0.5286 - val_loss: 40688695640064.0000 - val_accuracy: 0.6452\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4602999603200.0000 - accuracy: 0.5571 - val_loss: 40607447777280.0000 - val_accuracy: 0.6452\n",
      "Run 34/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 116767817728.0000 - accuracy: 0.4857 - val_loss: 750719680.0000 - val_accuracy: 0.6774\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 231583137792.0000 - accuracy: 0.4571 - val_loss: 756132224.0000 - val_accuracy: 0.6774\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1803777474560.0000 - accuracy: 0.5143 - val_loss: 761307840.0000 - val_accuracy: 0.6774\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1827953704960.0000 - accuracy: 0.5429 - val_loss: 765184256.0000 - val_accuracy: 0.6774\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3422042193920.0000 - accuracy: 0.3857 - val_loss: 768712896.0000 - val_accuracy: 0.6774\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1423699476480.0000 - accuracy: 0.5000 - val_loss: 772991616.0000 - val_accuracy: 0.6774\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2617448071168.0000 - accuracy: 0.5000 - val_loss: 777743296.0000 - val_accuracy: 0.6774\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 791476240384.0000 - accuracy: 0.4429 - val_loss: 782416256.0000 - val_accuracy: 0.6774\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 984042504192.0000 - accuracy: 0.5286 - val_loss: 786864704.0000 - val_accuracy: 0.6774\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2564395106304.0000 - accuracy: 0.4571 - val_loss: 791000768.0000 - val_accuracy: 0.6774\n",
      "Run 35/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1606378979328.0000 - accuracy: 0.5286 - val_loss: 3410161408.0000 - val_accuracy: 0.5161\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 654976024576.0000 - accuracy: 0.5714 - val_loss: 3408325632.0000 - val_accuracy: 0.5161\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1147499839488.0000 - accuracy: 0.5714 - val_loss: 3407493120.0000 - val_accuracy: 0.5161\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1135511207936.0000 - accuracy: 0.5286 - val_loss: 3407265536.0000 - val_accuracy: 0.5161\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 711093190656.0000 - accuracy: 0.5429 - val_loss: 3406447616.0000 - val_accuracy: 0.5161\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 704693207040.0000 - accuracy: 0.5857 - val_loss: 3405379584.0000 - val_accuracy: 0.5161\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 297418391552.0000 - accuracy: 0.5571 - val_loss: 3404947712.0000 - val_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 736255213568.0000 - accuracy: 0.5429 - val_loss: 3404059136.0000 - val_accuracy: 0.5161\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 629084454912.0000 - accuracy: 0.5429 - val_loss: 3403738368.0000 - val_accuracy: 0.5161\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 405644279808.0000 - accuracy: 0.5714 - val_loss: 3403359488.0000 - val_accuracy: 0.5161\n",
      "Run 36/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3149504970752.0000 - accuracy: 0.4857 - val_loss: 2792545536.0000 - val_accuracy: 0.4516\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3012844847104.0000 - accuracy: 0.4714 - val_loss: 2794045952.0000 - val_accuracy: 0.4516\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4188452945920.0000 - accuracy: 0.4571 - val_loss: 2795600384.0000 - val_accuracy: 0.4516\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4149453258752.0000 - accuracy: 0.5429 - val_loss: 2796811008.0000 - val_accuracy: 0.4516\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3586818310144.0000 - accuracy: 0.5143 - val_loss: 2797812224.0000 - val_accuracy: 0.4516\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3974643318784.0000 - accuracy: 0.5000 - val_loss: 2799262464.0000 - val_accuracy: 0.4516\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2826682761216.0000 - accuracy: 0.5286 - val_loss: 2800642304.0000 - val_accuracy: 0.4516\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1077105197056.0000 - accuracy: 0.4571 - val_loss: 2801564416.0000 - val_accuracy: 0.4516\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2835313852416.0000 - accuracy: 0.5000 - val_loss: 2802546176.0000 - val_accuracy: 0.4516\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4066278113280.0000 - accuracy: 0.4857 - val_loss: 2803899392.0000 - val_accuracy: 0.4516\n",
      "Run 37/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5237137997824.0000 - accuracy: 0.5571 - val_loss: 436351936.0000 - val_accuracy: 0.5161\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4682609065984.0000 - accuracy: 0.5571 - val_loss: 434999424.0000 - val_accuracy: 0.5161\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 877574553600.0000 - accuracy: 0.5857 - val_loss: 434316320.0000 - val_accuracy: 0.5161\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 662012297216.0000 - accuracy: 0.5714 - val_loss: 434155904.0000 - val_accuracy: 0.5161\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 800876396544.0000 - accuracy: 0.6000 - val_loss: 434072864.0000 - val_accuracy: 0.5161\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2008821006336.0000 - accuracy: 0.5857 - val_loss: 433433184.0000 - val_accuracy: 0.5161\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1825055440896.0000 - accuracy: 0.5714 - val_loss: 432755744.0000 - val_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1134794768384.0000 - accuracy: 0.6000 - val_loss: 431615200.0000 - val_accuracy: 0.5161\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 698395328512.0000 - accuracy: 0.5143 - val_loss: 430353248.0000 - val_accuracy: 0.5161\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 153632899072.0000 - accuracy: 0.5857 - val_loss: 429087360.0000 - val_accuracy: 0.5161\n",
      "Run 38/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2738315329536.0000 - accuracy: 0.4286 - val_loss: 4256253184.0000 - val_accuracy: 0.4839\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1978132987904.0000 - accuracy: 0.4143 - val_loss: 4262529024.0000 - val_accuracy: 0.4839\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3230071259136.0000 - accuracy: 0.4714 - val_loss: 4267734016.0000 - val_accuracy: 0.4839\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2939080671232.0000 - accuracy: 0.3857 - val_loss: 4272009728.0000 - val_accuracy: 0.4839\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3155975208960.0000 - accuracy: 0.4429 - val_loss: 4276184064.0000 - val_accuracy: 0.4839\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3974641221632.0000 - accuracy: 0.4000 - val_loss: 4280728064.0000 - val_accuracy: 0.4839\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3633748115456.0000 - accuracy: 0.4143 - val_loss: 4285533184.0000 - val_accuracy: 0.4839\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1166986182656.0000 - accuracy: 0.4857 - val_loss: 4289793792.0000 - val_accuracy: 0.4839\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3485243539456.0000 - accuracy: 0.3571 - val_loss: 4294636544.0000 - val_accuracy: 0.4839\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3156377337856.0000 - accuracy: 0.4000 - val_loss: 4298966016.0000 - val_accuracy: 0.4839\n",
      "Run 39/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 366729691136.0000 - accuracy: 0.4286 - val_loss: 57472383451136.0000 - val_accuracy: 0.4194\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 668325773312.0000 - accuracy: 0.3714 - val_loss: 57445103697920.0000 - val_accuracy: 0.4194\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 147129679872.0000 - accuracy: 0.4857 - val_loss: 57435381301248.0000 - val_accuracy: 0.4194\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 441002000384.0000 - accuracy: 0.4571 - val_loss: 57424463527936.0000 - val_accuracy: 0.4194\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 333713178624.0000 - accuracy: 0.4000 - val_loss: 57436383739904.0000 - val_accuracy: 0.4194\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 838797688832.0000 - accuracy: 0.5000 - val_loss: 57440703873024.0000 - val_accuracy: 0.4194\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 797145432064.0000 - accuracy: 0.5143 - val_loss: 57444789125120.0000 - val_accuracy: 0.4194\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 849298653184.0000 - accuracy: 0.4714 - val_loss: 57440703873024.0000 - val_accuracy: 0.4194\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 400017489920.0000 - accuracy: 0.5143 - val_loss: 57425688264704.0000 - val_accuracy: 0.4194\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 147473989632.0000 - accuracy: 0.4857 - val_loss: 57408659390464.0000 - val_accuracy: 0.4194\n",
      "Run 40/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 348128837632.0000 - accuracy: 0.4714 - val_loss: 21305233506304.0000 - val_accuracy: 0.5806\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 342984654848.0000 - accuracy: 0.3429 - val_loss: 21275311341568.0000 - val_accuracy: 0.5806\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 318253694976.0000 - accuracy: 0.4286 - val_loss: 21265110794240.0000 - val_accuracy: 0.5806\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 215825563648.0000 - accuracy: 0.4286 - val_loss: 21243694678016.0000 - val_accuracy: 0.5806\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 295398146048.0000 - accuracy: 0.4286 - val_loss: 21243883421696.0000 - val_accuracy: 0.5806\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 370468716544.0000 - accuracy: 0.4286 - val_loss: 21231153709056.0000 - val_accuracy: 0.5806\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 276256620544.0000 - accuracy: 0.3857 - val_loss: 21218474328064.0000 - val_accuracy: 0.5806\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 252055224320.0000 - accuracy: 0.3857 - val_loss: 21211725692928.0000 - val_accuracy: 0.5806\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 810547609600.0000 - accuracy: 0.4429 - val_loss: 21173794504704.0000 - val_accuracy: 0.5806\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 393739042816.0000 - accuracy: 0.4000 - val_loss: 21133149601792.0000 - val_accuracy: 0.5806\n",
      "Run 41/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6474008363008.0000 - accuracy: 0.5571 - val_loss: 31051246206976.0000 - val_accuracy: 0.3871\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3734320709632.0000 - accuracy: 0.5857 - val_loss: 30960246587392.0000 - val_accuracy: 0.3871\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6460504276992.0000 - accuracy: 0.4714 - val_loss: 30874617774080.0000 - val_accuracy: 0.3871\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7098312163328.0000 - accuracy: 0.4571 - val_loss: 30793485254656.0000 - val_accuracy: 0.3871\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6248470151168.0000 - accuracy: 0.5286 - val_loss: 30716150677504.0000 - val_accuracy: 0.3871\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7133197238272.0000 - accuracy: 0.4857 - val_loss: 30631765475328.0000 - val_accuracy: 0.3871\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6231358439424.0000 - accuracy: 0.5143 - val_loss: 30549374664704.0000 - val_accuracy: 0.3871\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3323907801088.0000 - accuracy: 0.4857 - val_loss: 30473537454080.0000 - val_accuracy: 0.3871\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6748671836160.0000 - accuracy: 0.4714 - val_loss: 30399002574848.0000 - val_accuracy: 0.3871\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6439020527616.0000 - accuracy: 0.5143 - val_loss: 30322209062912.0000 - val_accuracy: 0.3871\n",
      "Run 42/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4112458448896.0000 - accuracy: 0.5714 - val_loss: 33339469725696.0000 - val_accuracy: 0.7097\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2777140953088.0000 - accuracy: 0.5714 - val_loss: 33251378855936.0000 - val_accuracy: 0.7097\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7448526585856.0000 - accuracy: 0.5429 - val_loss: 33158363873280.0000 - val_accuracy: 0.7097\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 7351775002624.0000 - accuracy: 0.5429 - val_loss: 33082056900608.0000 - val_accuracy: 0.7097\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6576548085760.0000 - accuracy: 0.5571 - val_loss: 33010061672448.0000 - val_accuracy: 0.7097\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 7215339012096.0000 - accuracy: 0.5286 - val_loss: 32924720168960.0000 - val_accuracy: 0.7097\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5562385301504.0000 - accuracy: 0.5143 - val_loss: 32835844964352.0000 - val_accuracy: 0.7097\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 5371104067584.0000 - accuracy: 0.4714 - val_loss: 32743490584576.0000 - val_accuracy: 0.7097\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 6339039330304.0000 - accuracy: 0.5714 - val_loss: 32659241697280.0000 - val_accuracy: 0.7097\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6857897803776.0000 - accuracy: 0.5857 - val_loss: 32570274217984.0000 - val_accuracy: 0.7097\n",
      "Run 43/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2583689166848.0000 - accuracy: 0.5000 - val_loss: 6526993408.0000 - val_accuracy: 0.2903\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4068560601088.0000 - accuracy: 0.5143 - val_loss: 6529818112.0000 - val_accuracy: 0.2903\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2778728759296.0000 - accuracy: 0.4571 - val_loss: 6532301312.0000 - val_accuracy: 0.2903\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1952475119616.0000 - accuracy: 0.5571 - val_loss: 6534994944.0000 - val_accuracy: 0.2903\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2312925609984.0000 - accuracy: 0.5000 - val_loss: 6537476608.0000 - val_accuracy: 0.2903\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2274721529856.0000 - accuracy: 0.4571 - val_loss: 6540526080.0000 - val_accuracy: 0.2903\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3160283283456.0000 - accuracy: 0.4714 - val_loss: 6543612416.0000 - val_accuracy: 0.2903\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 128172220416.0000 - accuracy: 0.5000 - val_loss: 6546108928.0000 - val_accuracy: 0.2903\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3076409262080.0000 - accuracy: 0.4857 - val_loss: 6548253696.0000 - val_accuracy: 0.2903\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3369168797696.0000 - accuracy: 0.5143 - val_loss: 6550404608.0000 - val_accuracy: 0.2903\n",
      "Run 44/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1305371869184.0000 - accuracy: 0.4000 - val_loss: 931835200.0000 - val_accuracy: 0.5484\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1647331770368.0000 - accuracy: 0.3857 - val_loss: 933163520.0000 - val_accuracy: 0.5484\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 224572047360.0000 - accuracy: 0.4143 - val_loss: 933983104.0000 - val_accuracy: 0.5484\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 43435622400.0000 - accuracy: 0.4143 - val_loss: 934750400.0000 - val_accuracy: 0.5484\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 199773257728.0000 - accuracy: 0.3714 - val_loss: 934892288.0000 - val_accuracy: 0.5484\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 80833839104.0000 - accuracy: 0.4571 - val_loss: 935092480.0000 - val_accuracy: 0.5484\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 39799947264.0000 - accuracy: 0.3857 - val_loss: 935323968.0000 - val_accuracy: 0.5484\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 48049512448.0000 - accuracy: 0.5000 - val_loss: 935765888.0000 - val_accuracy: 0.5484\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 192626556928.0000 - accuracy: 0.4429 - val_loss: 936329152.0000 - val_accuracy: 0.5484\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 105714221056.0000 - accuracy: 0.4286 - val_loss: 936615168.0000 - val_accuracy: 0.5484\n",
      "Run 45/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 90240229376.0000 - accuracy: 0.4571 - val_loss: 346050816.0000 - val_accuracy: 0.6452\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 202614407168.0000 - accuracy: 0.4000 - val_loss: 350163360.0000 - val_accuracy: 0.6452\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2478599045120.0000 - accuracy: 0.4571 - val_loss: 353949344.0000 - val_accuracy: 0.6452\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2493106880512.0000 - accuracy: 0.5143 - val_loss: 356803840.0000 - val_accuracy: 0.6452\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2621455466496.0000 - accuracy: 0.4286 - val_loss: 359968544.0000 - val_accuracy: 0.6452\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2472853635072.0000 - accuracy: 0.4429 - val_loss: 363462496.0000 - val_accuracy: 0.6452\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2462303387648.0000 - accuracy: 0.4714 - val_loss: 367258624.0000 - val_accuracy: 0.6452\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 307356532736.0000 - accuracy: 0.4286 - val_loss: 370469824.0000 - val_accuracy: 0.6452\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2981986566144.0000 - accuracy: 0.5286 - val_loss: 373216224.0000 - val_accuracy: 0.6452\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1739216125952.0000 - accuracy: 0.4429 - val_loss: 376010976.0000 - val_accuracy: 0.6452\n",
      "Run 46/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 532708851712.0000 - accuracy: 0.5000 - val_loss: 1288994048.0000 - val_accuracy: 0.5161\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 542521425920.0000 - accuracy: 0.4714 - val_loss: 1286718208.0000 - val_accuracy: 0.5161\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 749794623488.0000 - accuracy: 0.4714 - val_loss: 1284715520.0000 - val_accuracy: 0.5161\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 865614888960.0000 - accuracy: 0.4857 - val_loss: 1284249856.0000 - val_accuracy: 0.5161\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 644820566016.0000 - accuracy: 0.4714 - val_loss: 1283494528.0000 - val_accuracy: 0.5161\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 720519495680.0000 - accuracy: 0.5714 - val_loss: 1282922112.0000 - val_accuracy: 0.5161\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 631931863040.0000 - accuracy: 0.4857 - val_loss: 1282046336.0000 - val_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 899005677568.0000 - accuracy: 0.5143 - val_loss: 1280679552.0000 - val_accuracy: 0.5161\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 426394845184.0000 - accuracy: 0.5143 - val_loss: 1279931392.0000 - val_accuracy: 0.5161\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 379129430016.0000 - accuracy: 0.5286 - val_loss: 1279136128.0000 - val_accuracy: 0.5161\n",
      "Run 47/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2970864844800.0000 - accuracy: 0.5571 - val_loss: 6561515008.0000 - val_accuracy: 0.2903\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2841786449920.0000 - accuracy: 0.5286 - val_loss: 6562121728.0000 - val_accuracy: 0.2903\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 694981361664.0000 - accuracy: 0.5714 - val_loss: 6562043392.0000 - val_accuracy: 0.2903\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 593591795712.0000 - accuracy: 0.5429 - val_loss: 6562292224.0000 - val_accuracy: 0.2903\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 533486403584.0000 - accuracy: 0.5714 - val_loss: 6561918976.0000 - val_accuracy: 0.2903\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 548326408192.0000 - accuracy: 0.5286 - val_loss: 6562299392.0000 - val_accuracy: 0.2903\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 689888624640.0000 - accuracy: 0.5286 - val_loss: 6562133504.0000 - val_accuracy: 0.2903\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1750083829760.0000 - accuracy: 0.5000 - val_loss: 6561907200.0000 - val_accuracy: 0.2903\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 565218443264.0000 - accuracy: 0.4857 - val_loss: 6562846720.0000 - val_accuracy: 0.2903\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 329922478080.0000 - accuracy: 0.5000 - val_loss: 6564279296.0000 - val_accuracy: 0.2903\n",
      "Run 48/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 53ms/step - loss: 1074196250624.0000 - accuracy: 0.6000 - val_loss: 750472658944.0000 - val_accuracy: 0.6129\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2625310556160.0000 - accuracy: 0.5286 - val_loss: 770493382656.0000 - val_accuracy: 0.6129\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 628736851968.0000 - accuracy: 0.5857 - val_loss: 815221899264.0000 - val_accuracy: 0.6129\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 527715237888.0000 - accuracy: 0.4857 - val_loss: 869086920704.0000 - val_accuracy: 0.5806\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 755691225088.0000 - accuracy: 0.6429 - val_loss: 933849530368.0000 - val_accuracy: 0.5806\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 648582332416.0000 - accuracy: 0.5714 - val_loss: 993070415872.0000 - val_accuracy: 0.5806\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 822554066944.0000 - accuracy: 0.5857 - val_loss: 1043955253248.0000 - val_accuracy: 0.5806\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 531054559232.0000 - accuracy: 0.5571 - val_loss: 1109796585472.0000 - val_accuracy: 0.5806\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 718941388800.0000 - accuracy: 0.5143 - val_loss: 1169609719808.0000 - val_accuracy: 0.5806\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 520779759616.0000 - accuracy: 0.5429 - val_loss: 1203799195648.0000 - val_accuracy: 0.5806\n",
      "Run 49/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 89012748288.0000 - accuracy: 0.5143 - val_loss: 26377061400576.0000 - val_accuracy: 0.4839\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 15577307136.0000 - accuracy: 0.5143 - val_loss: 26389149384704.0000 - val_accuracy: 0.4839\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 20767834112.0000 - accuracy: 0.4714 - val_loss: 26400662749184.0000 - val_accuracy: 0.4839\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 119740612608.0000 - accuracy: 0.5000 - val_loss: 26413130317824.0000 - val_accuracy: 0.4839\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 45331546112.0000 - accuracy: 0.5000 - val_loss: 26422227763200.0000 - val_accuracy: 0.4839\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 22250086400.0000 - accuracy: 0.5714 - val_loss: 26429123198976.0000 - val_accuracy: 0.4839\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 28759240704.0000 - accuracy: 0.5286 - val_loss: 26433382514688.0000 - val_accuracy: 0.4839\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 21127976960.0000 - accuracy: 0.5286 - val_loss: 26443262197760.0000 - val_accuracy: 0.4839\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 31567702016.0000 - accuracy: 0.5143 - val_loss: 26454930751488.0000 - val_accuracy: 0.4839\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 34276648960.0000 - accuracy: 0.4857 - val_loss: 26433778876416.0000 - val_accuracy: 0.4839\n",
      "Run 50/10\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1756383412224.0000 - accuracy: 0.4429 - val_loss: 20022705520640.0000 - val_accuracy: 0.6129\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2362694959104.0000 - accuracy: 0.4714 - val_loss: 19951926640640.0000 - val_accuracy: 0.6129\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 514936635392.0000 - accuracy: 0.4286 - val_loss: 19907903225856.0000 - val_accuracy: 0.6129\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 168652144640.0000 - accuracy: 0.3714 - val_loss: 19865347817472.0000 - val_accuracy: 0.6129\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 289572257792.0000 - accuracy: 0.4143 - val_loss: 19843086548992.0000 - val_accuracy: 0.6129\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1227396349952.0000 - accuracy: 0.4000 - val_loss: 19817104932864.0000 - val_accuracy: 0.6129\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 1325550403584.0000 - accuracy: 0.4000 - val_loss: 19789395263488.0000 - val_accuracy: 0.6129\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3429086527488.0000 - accuracy: 0.4286 - val_loss: 19749182373888.0000 - val_accuracy: 0.6129\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 771132424192.0000 - accuracy: 0.4857 - val_loss: 19707813953536.0000 - val_accuracy: 0.6129\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 585532899328.0000 - accuracy: 0.4286 - val_loss: 19675039662080.0000 - val_accuracy: 0.6129\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def create_classification_model(input_dim, num_classes, dropout_rate=0.2, learning_rate=1e-5, weight_decay=1e-4):\n",
    "    classification_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(input_dim,)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(units=num_classes, activation='softmax')\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "    classification_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return classification_model\n",
    "\n",
    "X_train = df_train.iloc[:, :-1].values  \n",
    "y_train = df_train.iloc[:, -1].values  \n",
    "X_test = df_test.iloc[:, :-1].values\n",
    "y_test = df_test.iloc[:, -1].values\n",
    "\n",
    "\n",
    "results = []\n",
    "for run in range(50):\n",
    "    print(f\"Run {run + 1}/10\")\n",
    "    \n",
    "    model = create_classification_model(input_dim=X_train.shape[1], num_classes=len(np.unique(y_train)))\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=10,\n",
    "        batch_size=16,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"run\": run + 1,\n",
    "        \"accuracy\": history.history['val_accuracy'][-1],\n",
    "        \"loss\": history.history['loss'][-1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: Accuracy = 0.5484, Loss = 5285195808768.0000\n",
      "Run 2: Accuracy = 0.5161, Loss = 2081130414080.0000\n",
      "Run 3: Accuracy = 0.5484, Loss = 1376803487744.0000\n",
      "Run 4: Accuracy = 0.7097, Loss = 60822458368.0000\n",
      "Run 5: Accuracy = 0.3548, Loss = 95883509760.0000\n",
      "Run 6: Accuracy = 0.5484, Loss = 7856437329920.0000\n",
      "Run 7: Accuracy = 0.5161, Loss = 1600023822336.0000\n",
      "Run 8: Accuracy = 0.4516, Loss = 4997990842368.0000\n",
      "Run 9: Accuracy = 0.5161, Loss = 2107419131904.0000\n",
      "Run 10: Accuracy = 0.2903, Loss = 102523953152.0000\n",
      "Run 11: Accuracy = 0.4516, Loss = 352437862400.0000\n",
      "Run 12: Accuracy = 0.5484, Loss = 639905038336.0000\n",
      "Run 13: Accuracy = 0.4516, Loss = 195117793280.0000\n",
      "Run 14: Accuracy = 0.3226, Loss = 3535763712.0000\n",
      "Run 15: Accuracy = 0.5161, Loss = 1482666147840.0000\n",
      "Run 16: Accuracy = 0.5806, Loss = 7346634358784.0000\n",
      "Run 17: Accuracy = 0.5161, Loss = 7418848739328.0000\n",
      "Run 18: Accuracy = 0.6129, Loss = 684117852160.0000\n",
      "Run 19: Accuracy = 0.5806, Loss = 1882294583296.0000\n",
      "Run 20: Accuracy = 0.3871, Loss = 373914501120.0000\n",
      "Run 21: Accuracy = 0.3871, Loss = 1288103264256.0000\n",
      "Run 22: Accuracy = 0.4516, Loss = 5392195649536.0000\n",
      "Run 23: Accuracy = 0.5161, Loss = 7361938849792.0000\n",
      "Run 24: Accuracy = 0.5806, Loss = 2229078065152.0000\n",
      "Run 25: Accuracy = 0.5806, Loss = 3139071639552.0000\n",
      "Run 26: Accuracy = 0.4839, Loss = 1730642968576.0000\n",
      "Run 27: Accuracy = 0.4839, Loss = 487483015168.0000\n",
      "Run 28: Accuracy = 0.5484, Loss = 3721014804480.0000\n",
      "Run 29: Accuracy = 0.3548, Loss = 2954127474688.0000\n",
      "Run 30: Accuracy = 0.6452, Loss = 4329591537664.0000\n",
      "Run 31: Accuracy = 0.4516, Loss = 2924432064512.0000\n",
      "Run 32: Accuracy = 0.3871, Loss = 3752239824896.0000\n",
      "Run 33: Accuracy = 0.6452, Loss = 4602999603200.0000\n",
      "Run 34: Accuracy = 0.6774, Loss = 2564395106304.0000\n",
      "Run 35: Accuracy = 0.5161, Loss = 405644279808.0000\n",
      "Run 36: Accuracy = 0.4516, Loss = 4066278113280.0000\n",
      "Run 37: Accuracy = 0.5161, Loss = 153632899072.0000\n",
      "Run 38: Accuracy = 0.4839, Loss = 3156377337856.0000\n",
      "Run 39: Accuracy = 0.4194, Loss = 147473989632.0000\n",
      "Run 40: Accuracy = 0.5806, Loss = 393739042816.0000\n",
      "Run 41: Accuracy = 0.3871, Loss = 6439020527616.0000\n",
      "Run 42: Accuracy = 0.7097, Loss = 6857897803776.0000\n",
      "Run 43: Accuracy = 0.2903, Loss = 3369168797696.0000\n",
      "Run 44: Accuracy = 0.5484, Loss = 105714221056.0000\n",
      "Run 45: Accuracy = 0.6452, Loss = 1739216125952.0000\n",
      "Run 46: Accuracy = 0.5161, Loss = 379129430016.0000\n",
      "Run 47: Accuracy = 0.2903, Loss = 329922478080.0000\n",
      "Run 48: Accuracy = 0.5806, Loss = 520779759616.0000\n",
      "Run 49: Accuracy = 0.4839, Loss = 34276648960.0000\n",
      "Run 50: Accuracy = 0.6129, Loss = 585532899328.0000\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print(f\"Run {res['run']}: Accuracy = {res['accuracy']:.4f}, Loss = {res['loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6129032373428345"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred_probs = model.predict(X_test)  \n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=np.unique(y_train))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
